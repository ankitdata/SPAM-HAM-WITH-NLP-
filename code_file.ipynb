
# coding: utf-8

# # To Check the versions
# 
# 

# In[ ]:

import sys
import nltk
import pandas as pd
import sklearn
import numpy as np
print('Python:{}'.format(sys.version))
print('NLTK:{}'.format(nltk.__version__))
print('Scikit-learn:{}'.format(sklearn.__version__))
print('Numpy:{}'.format(np.__version__))
print('Pandas:{}'.format(pd.__version__))


# # Importing Dataset
# 

# df = pd.read_table('SMSSpamCollection',header = None )
# 

# # Headings and Info
# 

# In[ ]:

print(df.info())
print(df.head)


# # Check the class distribution

# In[ ]:

classes = df[0]
print(classes.value_counts())   


# ## Preprocess the Dataset
# # Convert class labels to binary values 0 = ham 1 = spam
# 

# from sklearn.preprocessing import LabelEncoder
# encoder = LabelEncoder()
# Y=encoder.fit_transform(classes)
# Y= encoder.fit_transform(classes)
# print(Y[:10])
# print(classes[:10])
# 

# In[ ]:

#store the sms Message data
text_message =df[1]
print(text_message[:10])


# # Using regular expression to replace email addresses ,urls, phone no
# 

# In[7]:


#replace email addresses with emailaddr.
processed = text_message.str.replace(r'^.+@[^\.].*\.[a-z]{2,}$','emailaddr')

#replace urls with web addresss
processed = processed.str.replace(r'^http\://[a-zA-Z0-9\-\.]+\.[a-zA-Z]{2,3}(/\s*)?$','webaddress')

#replace money symnbols with moneysymb
processed = processed.str.replace(r'Â£|\$', 'moneysymb')

#repalce 10 digit phone number with phonenumber
processed = processed.str.replace(r'^\(?[\d]{3}\)?[\s-]?[\d]{3}[\s-]?[\d]{4}$','phonenumber')

#replace normal with no
processed = processed.str.replace(r'\d+(\.\d+)?','number')


# # Removed punctuations
# 

# In[8]:

processed = processed.str.replace(r'[^\w\d\s]',' ')

#replace whitespcaes between terms with single space
processed = processed.str.replace(r'\s+',' ')

#remove leading and trailing withspaces
processed = processed.str.replace(r'^\s+|\s+?$','')


# # Changing words in lower case Eg hello HELLO
# 

# In[12]:

processed = processed.str.lower()
print(processed)


# In[11]:

nltk.download('stopwords')


# # Remove stopwords
# 

# In[13]:

from nltk.corpus import stopwords

stop_word = set(stopwords.words('english'))

processed = processed.apply(lambda x:' '.join(term for term in x.split() if term not in stop_word))


# In[14]:

#remove word stems using porter stemer
ps= nltk.PorterStemmer()
processed = processed.apply(lambda x:' '.join(ps.stem(term) for term in x.split()))


# In[16]:

from nltk.tokenize import word_tokenize
#creating a bag of words
all_words = []
for message in processed:
    words = word_tokenize(message)
    for w in words:
        all_words.append(w)

all_words = nltk.FreqDist(all_words)


# In[17]:

#we print the total number words and 15 most common words here
print ('Number of words:{}'.format(len(all_words)))
print ('Most common words:{}'.format(all_words.most_common(15)))


# In[18]:

#use the 1500 most common words as feature

word_features = list(all_words.keys())[:1500]


# In[19]:

#define a find_feature funtion
def find_features(message):
    words = word_tokenize(message)
    features = {}
    for word in word_features:
        features[word]= (word in words)
    return features

#example
feature = find_features(processed[0])
for key, value in feature.items():
    if value == True:
        print (key)


# In[20]:

#Cross checking
processed[0]


# In[21]:

#find feature for all message
message = list(zip(processed,Y))

#defined a seed for  reproducibity
seed = 1
np.random.seed = seed
np.random.shuffle(message)

#Call find feature function for each SMS message
featuresets = [(find_features(text),label) for (text,label) in message]


# # Spliting dataset into trainingset and testset using sklearn
# 

# In[22]:

from sklearn import model_selection
training, testing = model_selection.train_test_split(featuresets,test_size = 0.25, random_state = seed)


# In[23]:

print ('training:{}'.format(len(training)))
print ('testing:{}'.format(len(testing)))


# # Scikit-Learn Classifier with NLTK

# In[24]:

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix


# In[25]:

#here models are Define to train dataset (1)

names = [' K nearest Neighbors','Desision Tree','Random Forest','Logistic Regression','SGD Classfier','Naive Bayes','SVM Liner']

classifier = [
    KNeighborsClassifier(),
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    LogisticRegression(),
    SGDClassifier(max_iter = 100),
    MultinomialNB(),
    SVC(kernel = 'linear')
    
]
model = zip(names, classifier)
print(model)


# # Ensemble method voting classifier

# In[26]:


from nltk.classify.scikitlearn import SklearnClassifier
    
for name, model in model:
    nltk_model = SklearnClassifier(model)
    nltk_model.train(training)
    accuracy = nltk.classify.accuracy(nltk_model,testing) * 100
    print('Ensemble Method :Accuracy:{}'.format(accuracy))


# In[27]:

#here models are Define to train dataset (2)

from sklearn.ensemble import VotingClassifier

names = [' K nearest Neighbors','Desision Tree','Random Forest','Logistic Regression','SGD Classfier','Naive Bayes','SVM Liner']

classifier = [
    KNeighborsClassifier(),
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    LogisticRegression(),
    SGDClassifier(max_iter = 100),
    MultinomialNB(),
    SVC(kernel = 'linear')
    
]
model = list(zip(names, classifier))
print(model)

# ensemble method voting classifier

from nltk.classify.scikitlearn import SklearnClassifier
nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = model, voting = 'hard', n_jobs=-1))
nltk_ensemble.train(training)
accuracy = nltk.classify.accuracy(nltk_ensemble, testing) * 100
print('Ensemble Method :Accuracy:{}'.format(accuracy))


# In[33]:

# make class label prediction for testing set
txt_features, label = zip(*testing)

prediction = nltk_ensemble.classify_many(txt_features)


# # Confusion matrix

# In[35]:

# print a confusion matrix and a classifier report
print(classification_report(label,prediction))

pd.DataFrame(
    confusion_matrix(label, prediction),
    index=[['actual','actual'],['ham','spam']],
    columns = [['prediction','prediction'],['ham','spam']]
)

